model:
  backbone: efficientnet_b3
  freeze_backbone: false       # Fine-tune all layers
  dropout_rate: 0.4
  
training:
  epochs: 20 # Change this to 40
  batch_size: 64
  lr: 0.00008
  weight_decay: 0.02
  num_workers: 4
  device: mps
  mixed_precision: true
  
augmentation:
  enabled: true
  intensity: medium
  techniques:
    - random_flip
    - random_rotation: 20
    - color_jitter: 0.2
    - gaussian_blur
    - random_affine: 0.1
    
early_stopping:
  patience: 8
  monitor: val_loss
  min_delta: 0.001
  
learning_rate_schedule:
  type: cosine_annealing
  T_max: 40
  min_lr: 0.00001
  
data:
  train_split: 0.7
  val_split: 0.2
  test_split: 0.1