# =============================================================================
# Skin Lesion Classification Configuration
# =============================================================================
# EfficientNet-V2 based classifier for HAM10000 dataset

# -----------------------------------------------------------------------------
# Data Configuration
# -----------------------------------------------------------------------------
data:
  root: data/HAM10000
  images_dir: data/HAM10000/images
  labels_csv: data/HAM10000/labels.csv
  split_seed: 42            # Random seed for data splitting (can differ from training seed)
  val_size: 0.15
  test_size: 0.15
  lesion_aware: true        # Prevent lesion-level data leakage

# -----------------------------------------------------------------------------
# Model Configuration
# -----------------------------------------------------------------------------
model:
  name: efficientnet_v2      # EfficientNet-V2 Small (hardcoded)
  num_classes: 7
  image_size: 224
  pretrained: true
  head_type: acrnn          # Attention-based Conv Recurrent NN classification head
  dropout_rate: 0.35        # ↓ Reduced (was choking learning at 0.65)
  freeze_backbone: false

# -----------------------------------------------------------------------------
# Training Configuration
# -----------------------------------------------------------------------------
training:
  seed: 42
  batch_size: 48    
  epochs: 40                # Maximum epochs (or use two-stage training below)
  lr: 0.0003                # ↑ Better for EfficientNet fine-tuning
  weight_decay: 0.02        # ↓ Balanced L2 regularization
  
  # Two-Stage Training
  stage1_epochs: 5          # Warm-up stage with higher LR
  stage1_lr: 0.001
  stage1_weight_decay: 0.01
  stage2_epochs: 35         # Fine-tuning stage with lower LR
  stage2_lr: 0.00025
  stage2_weight_decay: 0.02
  
  num_workers: 4
  use_amp: false            # MPS doesn't support AMP efficiently
  use_torch_compile: false  # Disabled for MPS (backward pass issues)
  use_weighted_sampling: true
  fast_mode: true           # Disable deterministic operations for speed
  augmentation: medium      # Options: light, medium, heavy, domain
  early_stopping_patience: 6
  prefetch_factor: 2        # Prefetch batches for better pipeline
  persistent_workers: true  # Keep workers alive between epochs

  # Feature Caching (Stage-2 Only)
  # Stage 1 trains the full model normally (backbone unfrozen).
  # At the stage 1→2 transition, the backbone is frozen and its features
  # are extracted/cached to disk. Stage 2 then trains only the classifier
  # head from cached features (~5-10x faster per epoch).
  # Requires two-stage training (stage1_epochs + stage2_epochs).
  feature_cache:
    enabled: true           # Enable stage-2 feature caching
    cache_dir: data/feature_cache  # Directory to store cached features
    rebuild: false           # Force rebuild cache even if valid cache exists
    batch_size: 128          # Batch size for cached feature training (can be larger)

  # Learning Rate Scheduler
  scheduler:
    type: cosine
    T_0: 20
    T_mult: 1
    eta_min: 0.00001
    warmup_pct: 0.05

  # Mixup Data Augmentation
  mixup:
    enabled: true           # Enable mixup augmentation
    alpha: 1.0               # Beta distribution parameter (0.2-1.0 recommended)

  # CutMix Data Augmentation
  cutmix:
    enabled: true           # Enable cutmix augmentation
    alpha: 1.0               # Beta distribution parameter (0.2-1.0 recommended)

  mixup_prob: 0.5            # Probability of mixup vs cutmix (when both enabled)

  # Exponential Moving Average (EMA)
  ema:
    enabled: true           # Enable model EMA for better generalization
    decay: 0.9999            # EMA decay rate (0.999-0.9999 recommended)
    use_for_eval: true       # Use EMA model for validation (recommended)
    save_best: true          # Save EMA weights in best checkpoint

# -----------------------------------------------------------------------------
# Loss Function
# -----------------------------------------------------------------------------
loss:
  type: cross_entropy
  label_smoothing: 0.05     # ↓ Prevents overconfidence without suppressing signal

# -----------------------------------------------------------------------------
# Data Augmentation (Dermatoscopy-Safe)
# -----------------------------------------------------------------------------
augmentation:
  enabled: true
  intensity: medium
  techniques:
    - random_horizontal_flip: 0.5
    - random_vertical_flip: 0.3
    - random_rotation: 25
    - color_jitter:
        brightness: 0.2
        contrast: 0.2
        saturation: 0.2
        hue: 0.1
    - gaussian_blur: 0.1
    - random_affine:
        degrees: 15
        translate: 0.1
        scale: [0.9, 1.1]
    - cutout: 0.1

# -----------------------------------------------------------------------------
# Evaluation Configuration
# -----------------------------------------------------------------------------
evaluation:
  batch_size: 96
  metrics:
    - accuracy
    - precision
    - recall
    - f1_score
    - roc_auc
    - confusion_matrix
  
  # Test-Time Augmentation (TTA)
  tta:
    enabled: true                     # Enable TTA for more robust predictions
    mode: medium                      # Options: light (4 augs), medium (8 augs), full (all)
    aggregation: mean                 # Options: mean, geometric_mean, max
  
  # Ensemble Prediction
  ensemble:
    enabled: true                     # Enable ensemble from multiple checkpoints
    checkpoints: []                   # List of checkpoint paths
    weights: null                     # Optional weights (null = uniform)
    aggregation: weighted_mean        # Options: mean, weighted_mean, geometric_mean

# -----------------------------------------------------------------------------
# Output Configuration
# -----------------------------------------------------------------------------
output:
  save_best_only: true
  log_interval: 10
  save_training_history: true
